{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d570c39b-34e2-4c21-a7dc-57ec9e46f8a9",
   "metadata": {},
   "source": [
    "### \"Шапка\" с названием проекта\n",
    "\n",
    "В этой ячейке вы найдете оглавление и ключевые этапы работы, которые помогут вам ориентироваться в процессе выполнения проекта. Проект разделен на пять основных этапов, четыре из которых (этапы 2, 3, 4 и 5) вам предлагается выполнить в этом Jupyter Notebook:\n",
    "\n",
    "- Подготовка среды MLflow - Первый шаг, подготовка и запуск сервисов MLflow, был выполнен вне ноутбука и оформлен в виде shell скрипта. Это основа для работы с экспериментами и логирования результатов ваших моделей.\n",
    "\n",
    "- Этап 2 - Исследовательский Анализ Данных (EDA): На этом этапе вы проведете тщательный анализ данных, чтобы лучше понять их структуру и особенности.\n",
    "\n",
    "- Этап 3 - Генерация Признаков и Обучение Модели: После анализа данных вы сгенерируете новые признаки и обучите модель, используя эти признаки.\n",
    "\n",
    "- Этап 4 - Отбор Признаков и Обучение Модели: На этом шаге вы отберете наиболее значимые признаки и снова обучите модель для улучшения ее качества.\n",
    "\n",
    "- Этап 5 - Подбор Гиперпараметров и Обучение Финальной Версии Модели: Финальный этап проекта посвящен оптимизации гиперпараметров для достижения максимального качества модели.\n",
    "\n",
    "Для удобства навигации и организации работы, пожалуйста, следуйте оглавлению и рекомендациям, описанным в каждом этапе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f78379",
   "metadata": {},
   "source": [
    "> ### Важно: Переобучение моделей\n",
    "> На каждом этапе проекта, где требуется переобучение модели, важно не просто выполнить эту процедуру, но и тщательно проверить качество модели на соответствующих выборках. Это включает в себя анализ метрик качества, визуализацию результатов, сравнение с предыдущими моделями и, при необходимости, корректировку."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7e2d2",
   "metadata": {},
   "source": [
    "> ### Важно: Разделение выборок\n",
    "> Перед началом выполнения вашего проекта важно правильно подготовить данные, разделив их на подвыборки. Это позволит оценить производительность модели более объективно и управлять риском переобучения. В зависимости от ваших целей и доступных данных, вы можете использовать различные стратегии разделения:\n",
    "\n",
    "1. Разделение на train/val/test: Это классический подход, где данные делятся на три части. Обучающая выборка (train) используется для первичного обучения моделей, валидационная (val) - для настройки гиперпараметров и выбора лучшей модели, а тестовая (test) - для финальной оценки производительности модели. Такой подход идеален, если у вас достаточно данных, чтобы разделить их и каждая из выборок была репрезентативна.\n",
    "\n",
    "2. Разделение на train/test с кросс-валидацией на train: Если данных недостаточно для трех подвыборок, можно ограничиться разделением на обучающую и тестовую выборки. В этом случае кросс-валидация на обучающей выборке поможет оценить стабильность модели и подобрать гиперпараметры.\n",
    "\n",
    "Определение способа разделения данных: Выбор метода разбиения данных на подвыборки — train, validation и test — должен быть обоснован особенностями вашего набора данных и задачами проекта. Возможные методы разделения, включая различные стратегии и правила, подробно описаны в [документации scikit-learn по разбиению данных](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py). Вы можете следовать этим примерам или разработать собственный метод, исходя из специфики ваших данных.\n",
    "\n",
    "Ваша задача - выбрать подходящий метод разделения данных исходя из объема и специфики ваших данных. Помните, что финальные метрики качества модели мы будем оценивать на тестовой выборке. Промежуточные результаты после каждого этапа проекта (например, после настройки гиперпараметров) следует оценивать на валидационной выборке, если таковая имеется. Это поможет вам корректно настроить модель перед финальной оценкой её производительности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c549e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделайте разделение изначального набора данных в этой ячейке\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 64\n",
    "\n",
    "df = pd.read_csv('initial_data.csv')\n",
    "\n",
    "features = df.drop(columns=['price']).columns.to_list()\n",
    "target = ['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[features],\n",
    "    df[target],\n",
    "    test_size=0.2,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(f\"Признаки: {features}\")\n",
    "print(f\"Таргет: {target}\")\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6393164-6b5e-40ab-9ad8-e518a96967d9",
   "metadata": {},
   "source": [
    "#### Этап 2: Исследовательский Анализ Данных (EDA)\n",
    "На этом этапе ваша задача - провести тщательный исследовательский анализ данных (EDA), чтобы глубже понять особенности и связи в предоставленном наборе данных. В процессе EDA вы должны обратить внимание на три ключевых аспекта, о которых мы говорили в теме 3 курса. Очень важно, чтобы все результаты вашего исследования, включая визуализации, статистический анализ и предварительные выводы, были аккуратно залогированы в MLflow.\n",
    "\n",
    "Для более организованного исследования предлагаем следующие рекомендуемые шаги:\n",
    "- Понимание данных: Первоначально ознакомьтесь с данными, изучите типы данных, проверьте наличие пропущенных значений.\n",
    "- Визуализация данных: Используйте графики и диаграммы для визуализации распределений признаков и возможных взаимосвязей между ними.\n",
    "- Статистический анализ: Примените статистические методы для изучения центральных тенденций, разброса и корреляций между признаками.\n",
    "- Предварительные выводы: На основе проведённого анализа сформулируйте предварительные выводы о данных, которые помогут в дальнейшем этапе моделирования.\n",
    "\n",
    "Помните, что EDA - это итеративный процесс, в котором вы можете возвращаться к предыдущим шагам для дополнительного анализа, если это будет необходимо. Все находки и выводы должны быть чётко зафиксированы и легко доступны для команды проекта.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd48e1fb-ff2a-41de-aa49-c7b5df19b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Загрузка данных\n",
    "# Загрузка была выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd00195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2. Общий обзор датасета\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6223f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# первые пять строк\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad3cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# последние пять строк\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d7e3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Анализ признаков для модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab442b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c66bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5dda59",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_collection = {}\n",
    "for col in df.columns:\n",
    "    unique_num = len(df[col].unique())\n",
    "    unique_collection[col] = unique_num\n",
    "\n",
    "unique_collection = dict(sorted(unique_collection.items(), key=lambda x: x[1], reverse=True))\n",
    "unique_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dddcbbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "ASSETS_DIR = \"assets\" \n",
    "if not os.path.exists(ASSETS_DIR):\n",
    "    os.makedir(ASSETS_DIR)\n",
    "sns.set_style(\"white\")\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15005a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"building_id\"\n",
    "\n",
    "cat_columns = [\n",
    "    \"building_type_int\",\n",
    "    'rooms',\n",
    "    'floor', \n",
    "    'floors_total',\n",
    "    'flats_count'\n",
    "]\n",
    "\n",
    "binary_columns = [\"is_apartment\", \n",
    "                  \"has_elevator\"]\n",
    "\n",
    "num_columns = ['ceiling_height', \n",
    "               'kitchen_area', \n",
    "               'living_area', \n",
    "               'total_area']\n",
    "\n",
    "geo_columns = ['latitude', \n",
    "               'longitude']\n",
    "\n",
    "stat = [\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522bb2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# график количества уникальных building_id в зависимости от фичей cat_columns (гистограммы):\n",
    "\n",
    "fig, axs = plt.subplots(3, 2)\n",
    "fig.set_size_inches(16.5, 12.5, forward=True)\n",
    "fig.tight_layout(pad=3.6)\n",
    "\n",
    "y = \"building_id\"\n",
    "\n",
    "x = \"building_type_int\"\n",
    "agg_df = pd.DataFrame(df.groupby(x).agg(stat)[y]).reset_index()\n",
    "sns.barplot(\n",
    "    data=agg_df,\n",
    "    x=x,\n",
    "    y=stat[0],\n",
    "    ax=axs[0, 0]\n",
    ")\n",
    "axs[0, 0].set_title(f'Count {y} by {x}')\n",
    "\n",
    "x = \"rooms\"\n",
    "agg_df = pd.DataFrame(df.groupby(x).agg(stat)[y]).reset_index()\n",
    "sns.barplot(\n",
    "    data=agg_df,\n",
    "    x=x,\n",
    "    y=stat[0],\n",
    "    ax=axs[0, 1]\n",
    ")\n",
    "axs[0, 1].set_title(f'Count {y} by {x}')\n",
    "\n",
    "x = \"floor\"\n",
    "agg_df = pd.DataFrame(df.groupby(x).agg(stat)[y]).reset_index()\n",
    "sns.barplot(\n",
    "    data=agg_df,\n",
    "    x=x,\n",
    "    y=stat[0],\n",
    "    ax=axs[1, 0]\n",
    ")\n",
    "axs[1, 0].set_title(f'Count {y} by {x}')\n",
    "\n",
    "x = \"floors_total\"\n",
    "agg_df = pd.DataFrame(df.groupby(x).agg(stat)[y]).reset_index()\n",
    "sns.barplot(\n",
    "    data=agg_df,\n",
    "    x=x,\n",
    "    y=stat[0],\n",
    "    ax=axs[1, 1]\n",
    ")\n",
    "axs[1, 1].set_title(f'Count {y} by {x}')\n",
    "\n",
    "x = \"flats_count\"\n",
    "agg_df = pd.DataFrame(df.groupby(x).agg(stat)[y]).reset_index()\n",
    "sns.barplot(\n",
    "    data=agg_df,\n",
    "    x=x,\n",
    "    y=stat[0],\n",
    "    ax=axs[2, 0]\n",
    ")\n",
    "axs[2,0].set_title(f'Count {y} by {x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea457e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# таблица-воронка для бинарных колонок с подсчётом количества уникальных building_id\n",
    "df.groupby(binary_columns).agg(stat[0])[x].reset_index().sort_values(\n",
    "    by=x, ascending=False\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb06ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# тепловая карта бинарных признаков\n",
    "heat_df = df[binary_columns].apply(pd.Series.value_counts).T\n",
    "sns.heatmap(heat_df)\n",
    "plt.savefig(os.path.join(ASSETS_DIR, 'cat_features_2_binary_heatmap'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c079d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Числовые\n",
    "\n",
    "x = \"build_year\"\n",
    "\n",
    "num_columns = ['ceiling_height', \n",
    "               'kitchen_area', \n",
    "               'living_area', \n",
    "               'total_area']\n",
    "\n",
    "stats = [\"mean\", \"median\", lambda x: x.mode().iloc[0]]\n",
    "\n",
    "ceiling_height_agg = df[[x] + [num_columns[0]]].groupby([x]).agg(stats).reset_index()\n",
    "ceiling_height_agg.columns = ceiling_height_agg.columns.droplevel()\n",
    "ceiling_height_agg.columns = [x, \"ceiling_height_mean\", \"ceiling_height_median\", \"ceiling_height_mode\"]\n",
    "\n",
    "kitchen_area_agg = df[[x] + [num_columns[1]]].groupby([x]).agg(stats).reset_index()\n",
    "kitchen_area_agg.columns = kitchen_area_agg.columns.droplevel()\n",
    "kitchen_area_agg.columns = [x, \"kitchen_area_mean\", \"kitchen_area_median\", \"kitchen_area_mode\"]\n",
    "\n",
    "living_area_agg = df[[x] + [num_columns[2]]].groupby([x]).agg(stats).reset_index()\n",
    "living_area_agg.columns = living_area_agg.columns.droplevel()\n",
    "living_area_agg.columns = [x, \"living_area_mean\", \"living_area_median\", \"living_area_mode\"]\n",
    "\n",
    "total_area_agg = df[[x] + [num_columns[3]]].groupby([x]).agg(stats).reset_index()\n",
    "total_area_agg.columns = total_area_agg.columns.droplevel()\n",
    "total_area_agg.columns = [x, \"total_area_mean\", \"total_area_median\", \"total_area_mode\"]\n",
    "\n",
    "ceiling_height_agg = ceiling_height_agg[ceiling_height_agg[\"build_year\"] > 1950].sort_values(\"build_year\")\n",
    "kitchen_area_agg = kitchen_area_agg[kitchen_area_agg[\"build_year\"] > 1950].sort_values(\"build_year\")\n",
    "living_area_agg = living_area_agg[living_area_agg[\"build_year\"] > 1950].sort_values(\"build_year\")\n",
    "total_area_agg = total_area_agg[total_area_agg[\"build_year\"] > 1950].sort_values(\"build_year\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.set_size_inches(16.5, 12.5, forward=True)\n",
    "fig.tight_layout(pad=3.6)\n",
    "\n",
    "# построение линейных графиков для ceiling_height\n",
    "sns.lineplot(ceiling_height_agg, ax=axs[0,0], x=x, y='ceiling_height_mean')\n",
    "sns.lineplot(ceiling_height_agg, ax=axs[0,0], x=x, y=\"ceiling_height_median\")\n",
    "sns.lineplot(ceiling_height_agg, ax=axs[0,0], x=x, y=\"ceiling_height_mode\")\n",
    "axs[0,0].set_title(f\"Count statistics for {num_columns[0]} by {x}\")\n",
    "\n",
    "# построение линейных графиков для kitchen_area\n",
    "sns.lineplot(kitchen_area_agg, ax=axs[0,1], x=x, y='kitchen_area_mean')\n",
    "sns.lineplot(kitchen_area_agg, ax=axs[0,1], x=x, y=\"kitchen_area_median\")\n",
    "sns.lineplot(kitchen_area_agg, ax=axs[0,1], x=x, y=\"kitchen_area_mode\")\n",
    "axs[0,1].set_title(f\"Count statistics for {num_columns[1]} by {x}\")\n",
    "\n",
    "# построение линейных графиков для living_area\n",
    "sns.lineplot(living_area_agg, ax=axs[1,0], x=x, y='living_area_mean')\n",
    "sns.lineplot(living_area_agg, ax=axs[1,0], x=x, y=\"living_area_median\")\n",
    "sns.lineplot(living_area_agg, ax=axs[1,0], x=x, y=\"living_area_mode\")\n",
    "axs[1,0].set_title(f\"Count statistics for {num_columns[2]} by {x}\")\n",
    "\n",
    "# построение линейных графиков для total_area\n",
    "sns.lineplot(total_area_agg, ax=axs[1,1], x=x, y='total_area_mean')\n",
    "sns.lineplot(total_area_agg, ax=axs[1,1], x=x, y=\"total_area_median\")\n",
    "sns.lineplot(total_area_agg, ax=axs[1,1], x=x, y=\"total_area_mode\")\n",
    "axs[1,1].set_title(f\"Count statistics for {num_columns[3]} by {x}\")\n",
    "\n",
    "# сохранение графика в файл\n",
    "plt.savefig(os.path.join(ASSETS_DIR, 'areas_and_height_by_date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3db3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geo_columns\n",
    "sns.scatterplot(data=df, x=\"latitude\", y=\"longitude\")\n",
    "\n",
    "# сохранение графика в файл\n",
    "plt.savefig(os.path.join(ASSETS_DIR, 'geo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85ddeabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Анализ целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9b0648",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[target].describe())\n",
    "\n",
    "price = df[df[\"price\"] < 1000000][\"price\"].dropna().astype(float)\n",
    "sns.displot(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e416a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Анализ целевой переменной в зависимости от различных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d3334",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = df[df[\"price\"] < 100000][[\"price\", binary_columns[0], binary_columns[1]]].dropna().astype(float)\n",
    "\n",
    "sns.displot(price, x=\"price\", hue=binary_columns[0])\n",
    "plt.savefig(os.path.join(ASSETS_DIR, 'price_vs_is_apartment'))\n",
    "\n",
    "sns.displot(price, x=\"price\", hue=binary_columns[1])\n",
    "plt.savefig(os.path.join(ASSETS_DIR, 'price_vs_has_elevator'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9487cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Выводы после EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ed4840",
   "metadata": {},
   "source": [
    "### EDA\n",
    "\n",
    "Типы данных в датасете: INT и FLOAT. \n",
    "\n",
    "Данные уже были предобработаны в проекте первого спринта, пропущенных значений нет.\n",
    "\n",
    "Были построены графики:\n",
    "\n",
    " - `cat_features_1.png`: количество зданий в разрезе фичей `building_type_int`, `rooms`, `floor`, `floors_total` и `flats_count`.\n",
    "По графикам видно, что в данных преобладают здания 4-го типа с 1-2-3 комнатными помещениями. Типов 0 и 3 мало. Также есть немного зданий с 5-6-7 комнатами. \n",
    "Этажи в основном с 1 по 10. Также есть высокие, но в пределах реального.\n",
    "Можем принять что, в этих фичах выбросов не наблюдается.\n",
    " - `cat_features_2_binary_heatmap.png`: визуальная оценка бинарных признаков.\n",
    "В основном, среди объектов преобладают не-квартиры с лифтами. Возможно это - отели или бизнес-центры. Квартир очень мало.\n",
    "Также, не будем считать их за выбросы.\n",
    " - `areas_and_height_by_date.png`: \n",
    "С годами растет высота потолков, но уменьшается площадь помещения.\n",
    " - `geo.png`:\n",
    "Геолокации объектов сгруппированы в одной области - без сюрпризов.\n",
    "\n",
    "Анализ целевой переменной:\n",
    "\n",
    "Цены на объекты - в основном до 100000. Можно убрать из обучения данные выше этой цены. \n",
    "По корреляции с `has_elevator` нельзя сказать, что цена растет с наличием лифтов. Интересных корреляций не замечено."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d8bda",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9027cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6 логирование артефактов в MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc614bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "EXPERIMENT_NAME = \"churn_marselkamilov_project_2\"\n",
    "RUN_NAME = \"model_baseline\"\n",
    "\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" #endpoint бакета от YandexCloud\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\") # получаем id ключа бакета, к которому подключён MLFlow, из .env\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\") # получаем ключ бакета, к которому подключён MLFlow, из .env\n",
    "\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "mlflow.set_registry_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    mlflow.log_artifact(\"project_template_sprint_2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0688e2-8a9b-4474-8dc1-b899a081bcec",
   "metadata": {},
   "source": [
    "#### Этап 3: Генерация Признаков и Обучение Новой Версии Модели\n",
    "После тщательного исследовательского анализа данных (EDA), вы, скорее всего, сформировали несколько гипотез относительно новых признаков, которые могут улучшить качество вашей модели. На этом этапе, мы предлагаем вам приступить к генерации новых признаков и последующему обучению модели, используя два подхода:\n",
    "\n",
    "Ручная генерация признаков: Используйте ваше понимание данных и результаты EDA для создания новых признаков.\n",
    "Автоматическая генерация признаков: Воспользуйтесь библиотеками для автоматической генерации признаков, чтобы облегчить и ускорить этот процесс.\n",
    "Важно: Для признаков, созданных вручную, рекомендуется использовать объекты sklearn, такие как Pipeline и ColumnTransformer. Это позволит автоматизировать процесс преобразования данных и облегчить поддержку вашего проекта.\n",
    "\n",
    "После генерации новых признаков, наступает время обучить новую версию вашей модели, используя эти признаки. Не забудьте залогировать все результаты, включая новые признаки, параметры модели и метрики качества, в MLflow для удобства отслеживания изменений и результатов.\n",
    "\n",
    "Рекомендуемые шаги:\n",
    "\n",
    "- Определение и генерация новых признаков на основе ваших гипотез.\n",
    "- Использование библиотек для автоматической генерации признаков, если это применимо.\n",
    "- Интеграция новых признаков в вашу модель с помощью Pipeline или ColumnTransformer для ручно созданных признаков.\n",
    "- Обучение новой версии модели с использованием всех доступных признаков.\n",
    "- Логирование результатов в MLflow для документирования и анализа эффективности новых признаков и модели.\n",
    "\n",
    "Этот этап проекта критически важен для повышения точности и эффективности вашей модели. Тщательная работа на этом этапе может существенно повлиять на итоговое качество моделирования.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abed98b-381b-456c-8f31-c31c2408c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 ручная генерация признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fbe0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    SplineTransformer, \n",
    "    QuantileTransformer, \n",
    "    RobustScaler,\n",
    "    PolynomialFeatures,\n",
    "    KBinsDiscretizer,\n",
    ")\n",
    "\n",
    "num_columns = ['ceiling_height', \n",
    "               'kitchen_area', \n",
    "               'living_area', \n",
    "               'total_area',\n",
    "                'rooms',\n",
    "                'floor', \n",
    "                'floors_total',\n",
    "                'flats_count']\n",
    "\n",
    "n_knots = 3\n",
    "degree_spline = 4\n",
    "n_quantiles=100\n",
    "degree = 3\n",
    "n_bins = 5\n",
    "encode = 'ordinal'\n",
    "strategy = 'uniform'\n",
    "subsample = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4478812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 оборачивание всех преобразований в объекты sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5894e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = ColumnTransformer(transformers=[('spl', SplineTransformer(n_knots=n_knots, degree=degree_spline), num_columns), \n",
    "                                                      ('q', QuantileTransformer(n_quantiles=n_quantiles), num_columns), \n",
    "                                                      ('rb', RobustScaler(), num_columns), \n",
    "                                                      ('pol', PolynomialFeatures(degree=degree), num_columns), \n",
    "                                                      ('kbd', KBinsDiscretizer(n_bins=n_bins, encode=encode, strategy=strategy, subsample=subsample), num_columns)])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, num_columns)], \n",
    "                                               n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0b61ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features = preprocessor.fit_transform(X_train)\n",
    "encoded_features_test = preprocessor.transform(X_test)\n",
    "\n",
    "transformed_df = pd.DataFrame(\n",
    "    encoded_features, \n",
    "    columns=preprocessor.get_feature_names_out()\n",
    ")\n",
    "transformed_df_test = pd.DataFrame(\n",
    "    encoded_features_test, \n",
    "    columns=preprocessor.get_feature_names_out()\n",
    ")\n",
    "\n",
    "transformed_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ce0336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 автоматическая генерация признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb51fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autofeat import AutoFeatRegressor\n",
    "transformations = [\"1/\", 'exp', 'log']\n",
    "af = AutoFeatRegressor(feateng_steps = 1,\n",
    "                       max_gb = 16,\n",
    "                       transformations = transformations)\n",
    "X_train_af = af.fit_transform(X_train, y_train)\n",
    "X_test_af = af.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = pd.concat([transformed_df, X_train_af], axis=1)\n",
    "X_test_features = pd.concat([transformed_df_test, X_test_af], axis=1)\n",
    "X_train_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3053373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 обучение новой версии модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e49fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "model = CatBoostRegressor(loss_function = 'RMSE')\n",
    "model.fit(X_train_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fdc28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "probas = model.predict(X_test_features)\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "r2 = r2_score(y_test, probas)\n",
    "neg_mse = mean_squared_error(y_test, probas)\n",
    "neg_mape = mean_absolute_percentage_error(y_test, probas)\n",
    "\n",
    "metrics[\"r2\"] = r2\n",
    "metrics[\"neg_mean_squared_error\"] = neg_mse\n",
    "metrics[\"neg_mean_absolute_percentage_error\"] = neg_mape\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = model.get_best_score()[\"learn\"]\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f5820bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 логирование артефактов в MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31729ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTRY_MODEL_NAME = \"project_model_generated_features\"\n",
    "\n",
    "# настройки для логирования в MLFlow\n",
    "pip_requirements = './requirements.txt'\n",
    "signature = mlflow.models.infer_signature(X_test, probas)\n",
    "input_example = X_test[:10]\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    mlflow.log_metrics(metrics) \n",
    "    mlflow.log_params(best_score)\n",
    "\n",
    "    model_info = mlflow.catboost.log_model(cb_model=model,\n",
    "        artifact_path=\"models\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        registered_model_name=REGISTRY_MODEL_NAME,\n",
    "        await_registration_for=60,\n",
    "        pip_requirements=pip_requirements\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9191a1-28e5-409f-8958-ad0536da2830",
   "metadata": {},
   "source": [
    "#### Этап 4: Отбор Признаков и Обучение Новой Версии Модели\n",
    "Создание новых признаков — это лишь часть работы. Следующий важный шаг — это убедиться в том, что каждый из этих признаков действительно вносит положительный вклад в качество модели. Некоторые признаки могут оказывать отрицательное влияние на модель, поэтому их следует исключить из анализа.\n",
    "\n",
    "На этом этапе, мы рекомендуем вам применить различные методы отбора признаков для того, чтобы определить и удалить те признаки, которые не улучшают качество вашей модели. Цель этого этапа — максимизировать производительность модели, удалив избыточные или неинформативные признаки.\n",
    "\n",
    "После тщательного отбора признаков, пора обучить новую версию вашей модели, уже без негативно влияющих на неё признаков. Важно залогировать результаты этого этапа, включая измененный набор признаков, параметры модели и полученные метрики качества, в MLflow для последующего анализа и сравнения.\n",
    "\n",
    "Рекомендуемые шаги:\n",
    "\n",
    "- Применение методов отбора признаков для идентификации и исключения признаков, ухудшающих качество модели.\n",
    "- Анализ влияния каждого признака на модель, чтобы понять, какие из них наиболее ценные.\n",
    "- Обучение новой версии модели без негативно влияющих признаков.\n",
    "- Логирование всех изменений и результатов в MLflow, включая конечный набор признаков, параметры модели и метрики качества.\n",
    "\n",
    "Этот этап не только поможет улучшить качество вашей модели, но и даст глубокое понимание о важности и влиянии отдельных признаков на результаты моделирования.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05402c42-78e0-4efe-86b2-8327409f1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Отбор признаков при помощи метода номер 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8327cf39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b66f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d5d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Отбор признаков при помощи метода номер 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c729b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a4ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2464f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Анализ отобранных признаков при помощи двух методов и формирование финального списка с признаками для модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2947cc17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc549c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec9e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 Обучение новой версии модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f749c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d4c530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9481f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.5 Логирование всех артефактов в MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b7cfcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377f1231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9995f97b-e99c-4a87-8a56-373ce5991beb",
   "metadata": {},
   "source": [
    "### Этап 5 - подбор гиперпараметров и обучение новой версии модели\n",
    "После того как мы уделили значительное внимание качеству модели через создание и отбор признаков, пришло время для финального штриха — подбора гиперпараметров. Этот этап является ключевым в финальной части проекта второго спринта, где ваша задача — оптимизировать гиперпараметры модели для достижения наилучшего качества.\n",
    "\n",
    "Рекомендуется подобрать гиперпараметры как минимум двумя различными методами (например, с использованием Grid Search и Random Search), чтобы вы могли сравнить результаты и выбрать наиболее эффективный набор гиперпараметров для вашей модели. После определения оптимальных гиперпараметров, наступает время обучить финальную версию модели, используя ваши новые признаки.\n",
    "\n",
    "Рекомендуемые шаги:\n",
    "\n",
    "- Выбор методов для подбора гиперпараметров: Определитесь с методами, которые вы будете использовать для подбора гиперпараметров (например, Grid Search, Random Search, Bayesian Optimization).\n",
    "- Подбор гиперпараметров: Примените выбранные методы для нахождения оптимальных значений гиперпараметров вашей модели.\n",
    "- Сравнение результатов: Анализируйте и сравнивайте результаты, полученные различными методами, для определения наилучшего набора гиперпараметров.\n",
    "- Обучение финальной модели: Используя выбранные гиперпараметры, обучите финальную версию вашей модели на новых признаках.\n",
    "- Документирование процесса и результатов: Залогируйте все шаги и результаты в MLflow, включая сравнение методов подбора гиперпараметров и характеристики финальной модели.\n",
    "\n",
    "Этот этап позволит вам максимально улучшить качество вашей модели перед финальной оценкой, предоставив полное понимание важности и влияния гиперпараметров на производительность модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4645bb1d-cc8f-41ef-a13d-21f08cd5c7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Подбор гиперпарметров при мощи метода номер 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3043446a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bea8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b2a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Подбор гиперпарметров при мощи метода номер 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64014d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f06136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056af6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 Формирование списка гиперпараметров для новой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54bbfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da63e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a0a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 Обуение финальной версии модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f1ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228904ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d6d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.5 Логирование артефактов в MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc6c8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846e989f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
